# Video-chatbot
An AI-powered Video + RAG Chatbot that recognizes faces, remembers past conversations via Pinecone, and chats naturally using Ollama or OpenAI â€” all in real time. Built with FastAPI, InsightFace, and Retrieval-Augmented Generation (RAG) for a human-like multimodal experience.

ğŸ§ ğŸ¥ Video + RAG Chatbot (with Face Recognition & Memory)
A multimodal AI assistant that combines:
ğŸ¥ Real-time face recognition (via InsightFace)
ğŸ’¬ Natural conversation through local LLMs (Ollama or OpenAI)
ğŸ§© Long-term memory using Pinecone + embeddings
ğŸ—£ï¸ Optional speech support (STT + TTS)
âš™ï¸ Built on FastAPI, WebSockets, and Python

âš™ï¸ Setup
1ï¸âƒ£ Clone the repo
git clone https://github.com/<your-username>/video-rag-chatbot.git
cd video-rag-chatbot

2ï¸âƒ£ Create and activate a virtual environment
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set up your .env
Create a .env file in the root directory:
# Pinecone
PINECONE_API_KEY=pcsk_********************************
PINECONE_INDEX=video-chatbot
# LLM (choose one)
OLLAMA_URL=http://localhost:11434/api/generate
# or, if using OpenAI:
# OPENAI_API_KEY=sk-proj-********************************

ğŸš€ Running the Server
uvicorn server:app --reload

Then visit:
http://127.0.0.1:8000/docs
for the interactive Swagger UI.


ğŸ“¸ Face Recognition Workflow
Each frame from the webcam is:
Sent via WebSocket â†’ /video-stream
Processed by detection.py using ArcFace
Matched to stored user embeddings in data/users/
Response: { "user": "Harshita", "active": true }





# Embeddings
EMBED_MODEL=all-MiniLM-L6-v2
